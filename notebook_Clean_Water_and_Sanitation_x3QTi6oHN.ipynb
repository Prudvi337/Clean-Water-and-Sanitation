{"cells": [{"metadata": {}, "cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\n\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='uCwWxNcbe605gjQUmewxN3avqpueiCWHKdyr31gq_6Qa',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.us-south.cloud-object-storage.appdomain.cloud')\n\nbucket = 'cleanwaterandsanitation-donotdelete-pr-hywaf9ektcwmgg'\nobject_key = 'water_potability.csv'\n\nbody = cos_client.get_object(Bucket=bucket,Key=object_key)['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndata= pd.read_csv(body)\ndata.head(10)\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Optional: Enable inline plotting for Jupyter notebooks\n%matplotlib inline\n", "execution_count": 15, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Get a summary of the dataset\ndata.info()\n\n# Statistical summary of the data\ndata.describe()\n\n# Check for missing values\ndata.isnull().sum()\n", "execution_count": 16, "outputs": [{"output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3276 entries, 0 to 3275\nData columns (total 10 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   ph               2785 non-null   float64\n 1   Hardness         3276 non-null   float64\n 2   Solids           3276 non-null   float64\n 3   Chloramines      3276 non-null   float64\n 4   Sulfate          2495 non-null   float64\n 5   Conductivity     3276 non-null   float64\n 6   Organic_carbon   3276 non-null   float64\n 7   Trihalomethanes  3114 non-null   float64\n 8   Turbidity        3276 non-null   float64\n 9   Potability       3276 non-null   int64  \ndtypes: float64(9), int64(1)\nmemory usage: 256.1 KB\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 16, "data": {"text/plain": "ph                 491\nHardness             0\nSolids               0\nChloramines          0\nSulfate            781\nConductivity         0\nOrganic_carbon       0\nTrihalomethanes    162\nTurbidity            0\nPotability           0\ndtype: int64"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Drop rows with missing values\ndata = data.dropna()\nfrom sklearn.preprocessing import StandardScaler\n\n# Initialize the scaler\nscaler = StandardScaler()\n\n# Select features for scaling (excluding the target variable 'Potability')\nfeatures = data.columns.drop('Potability')\ndata[features] = scaler.fit_transform(data[features])\nfrom sklearn.preprocessing import LabelEncoder\n\n# Initialize the encoder\nencoder = LabelEncoder()\n\n# Encode the target variable\ndata['Potability'] = encoder.fit_transform(data['Potability'])\n", "execution_count": 17, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.model_selection import train_test_split\n\n# Define features (X) and target variable (y)\nX = data.drop('Potability', axis=1)\ny = data['Potability']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n", "execution_count": 18, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.ensemble import RandomForestClassifier\n\n# Initialize the classifier\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the model\nmodel.fit(X_train, y_train)\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n\n# Evaluate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\n\n# Detailed classification report\nprint(classification_report(y_test, y_pred))\n", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "Accuracy: 65.26%\n              precision    recall  f1-score   support\n\n           0       0.65      0.84      0.73       231\n           1       0.65      0.40      0.50       172\n\n    accuracy                           0.65       403\n   macro avg       0.65      0.62      0.62       403\nweighted avg       0.65      0.65      0.63       403\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "import joblib\n\n# Save the trained model to a file\njoblib.dump(model, 'water_quality_model.pkl')\n", "execution_count": 20, "outputs": [{"output_type": "execute_result", "execution_count": 20, "data": {"text/plain": "['water_quality_model.pkl']"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.14", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}